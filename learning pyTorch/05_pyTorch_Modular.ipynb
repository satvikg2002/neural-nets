{"cells":[{"cell_type":"markdown","metadata":{"id":"ajKWYEAuNPcj"},"source":["# 05. Making PyTorch Modular\n","Ref - https://www.learnpytorch.io/05_pytorch_going_modular/"]},{"cell_type":"markdown","metadata":{"id":"p0c9TH_sN9Ox"},"source":["## What is going modular?  \n","Going modular involves turning notebook code (from a Jupyter Notebook or Google Colab notebook) into a series of different Python scripts that offer similar functionality.\n","\n","For example, we could turn our notebook code from a series of cells into the following Python files:\n","\n","*data_setup.py* - a file to prepare and download data if needed.  \n","*engine.py* - a file containing various training functions.  \n","*model_builder.py or model.py* - a file to create a PyTorch model.  \n","*train.py* - a file to leverage all other files and train a target PyTorch model.   \n","*utils.py* - a file dedicated to helpful utility functions."]},{"cell_type":"markdown","metadata":{},"source":["For example, you might be instructed to run code like the following in a terminal/command line to train a model:\n","\n","<code>python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS</code>"]},{"cell_type":"markdown","metadata":{},"source":["![image.png](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/05-python-train-command-line-annotated.png)"]},{"cell_type":"markdown","metadata":{},"source":["There are two notebooks for this section:\n","\n","1. Cell mode - this notebook is run as a traditional Jupyter Notebook/Google Colab notebook and is a condensed version of notebook 04.\n","2. Script mode - this notebook is the same as number 1 but with added functionality to turn each of the major sections into Python scripts, such as, data_setup.py and train.py."]},{"cell_type":"markdown","metadata":{},"source":["## Things to note\n","*Docstrings* - Writing reproducible and understandable code is important. And with this in mind, each of the functions/classes we'll be putting into scripts has been created with Google's Python docstring style in mind.\n","*Imports at the top of scripts* - Since all of the Python scripts we're going to create could be considered a small program on their own, all of the scripts require their input modules be imported at the start of the script for example:\n","\n","<code>\n","# Import modules required for train.py<br>     \n","import os<br>    \n","import torch<br>\n","import data_setup, engine, model_builder, utils<br>    \n","\n","from torchvision import transforms\n","</code>"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Getting Data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Did not find data\\pizza_steak_sushi directory, creating one...\n","Downloading pizza, steak, sushi data...\n","Unzipping pizza, steak, sushi data...\n"]}],"source":["import os\n","import requests\n","import zipfile\n","from pathlib import Path\n","\n","# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"pizza_steak_sushi\"\n","\n","# If the image folder doesn't exist, download it and prepare it... \n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory, creating one...\")\n","    image_path.mkdir(parents=True, exist_ok=True)\n","\n","# Download pizza, steak, sushi data\n","with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","    print(\"Downloading pizza, steak, sushi data...\")\n","    f.write(request.content)\n","\n","# Unzip pizza, steak, sushi data\n","with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","    print(\"Unzipping pizza, steak, sushi data...\") \n","    zip_ref.extractall(image_path)\n","\n","# Remove zip file\n","os.remove(data_path / \"pizza_steak_sushi.zip\")"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Create Datasets and DataLoaders (data_setup.py)\n","## 3. 3. Making a model (model_builder.py)\n","## 4. Creating train_step() and test_step() functions and train() to combine them\n","## 5. Creating a function to save the model (utils.py)\n","## 6. Train, evaluate and save the model (train.py)"]},{"cell_type":"markdown","metadata":{"id":"1Osav2eEOVzH"},"source":["To create train.py we'll go through the following steps:\n","\n","1. Import the various dependencies, namely torch, os, torchvision.transforms and all of the scripts from the going_modular directory, data_setup, engine, model_builder, utils.\n","2. *Note:* Since train.py will be inside the going_modular directory, we can import the other modules via import ... rather than from going_modular import ....\n","3. Setup various hyperparameters such as batch size, number of epochs, learning rate and number of hidden units (these could be set in the future via Python's argparse).\n","4. Setup the training and test directories.\n","5. Setup device-agnostic code.\n","6. Create the necessary data transforms.\n","7. Create the DataLoaders using data_setup.py.\n","8. Create the model using model_builder.py.\n","9. Setup the loss function and optimizer.\n","10. Train the model using engine.py.\n","11. Save the model using utils.py."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOr9VzzL4+FJ0viY+cCzfwn","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
